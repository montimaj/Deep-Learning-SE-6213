{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "HW2_Sayantan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montimaj/Deep-Learning-SE-6213/blob/master/HW2/HW2_Sayantan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1mUj8b19lpV",
        "colab_type": "text"
      },
      "source": [
        "# SYS ENG 6213 - Deep Learning and Advanced Neural Networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6agd8XtI9lpX",
        "colab_type": "text"
      },
      "source": [
        "### Implementation of two layer neural network for classification of MNIST data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMUjfyHu944Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59ea8ee9-e053-4cc8-f322-dd562e0896f4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HW2_Sayantan.ipynb  hw2_sayantan.py  layers.py\tMNIST_data  utils.pyc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd_avEPG-CnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bc12ba7-5749-4638-a416-f429cfa5394f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeS0X4kP-Ead",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "de4f6e2e-43b4-4e92-88b9-e7b54fa5e7f2"
      },
      "source": [
        "%cd 'drive/My Drive/SysEng 6213 Fall 2020 Sayantan Majumdar /HW2/'\n",
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/SysEng 6213 Fall 2020 Sayantan Majumdar /HW2/'\n",
            "/content/drive/.shortcut-targets-by-id/1xpWpUfn0NqGtbgAP_303jr6QW5RKzJPR/SysEng 6213 Fall 2020 Sayantan Majumdar /HW2\n",
            "HW2_Sayantan.ipynb  hw2_sayantan.py  layers.py\tMNIST_data  utils.pyc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qht_Pbuw9lpY",
        "colab_type": "text"
      },
      "source": [
        "In this homework you will be implementing a simple two layered neural network to recognize hand-written digits. Open the layers.py file. It has different functions which will be used for training the neural network. You need to complete each function with appropriate code in the spaces provided. You can check the correctness of your code by using the function calls below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOgTIqC9lpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the functions\n",
        "from layers import *\n",
        "from utils import *\n",
        "# Set up the packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-wV-UDBIYun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "19e3e295-12cf-4349-fd2d-8baf799aade2"
      },
      "source": [
        "# Test cell to check if user-defined functions from imported files work\n",
        "print(softmax(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09003057 0.24472847 0.66524096]\n",
            " [0.09003057 0.24472847 0.66524096]\n",
            " [0.09003057 0.24472847 0.66524096]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXovxjYT9lph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize values for check functions\n",
        "test_x = np.asarray([\n",
        "  [-0.000615  ,  0.0214419 , -0.36510585,  0.20082408],\n",
        "  [ 0.22389826,  0.14115274,  0.05578092,  0.1698094 ],\n",
        "  [-0.23772221,  0.00885403, -0.13013507,  0.02939912],\n",
        "  [ 0.05740505, -0.026481  ,  0.09055714, -0.51067097],\n",
        "  [ 0.02905955, -0.26222096,  0.23401101, -0.32704291]])\n",
        "test_w = np.asarray([\n",
        "  [ 0.14083526, -0.00589104, -0.01267299],\n",
        "  [ 0.2149024 ,  0.05601603,  0.22214587],\n",
        "  [-0.0246409 ,  0.01524164, -0.16539496],\n",
        "  [-0.07199102, -0.12796543,  0.2509505 ]])\n",
        "test_b = np.asarray([0.24348208,  0.02070011, -0.05303671])\n",
        "fs_scores = np.asarray([[ 0.24254239, -0.00935853,  0.06251788],\n",
        "       [ 0.29174967,  0.00640839,  0.0088702 ],\n",
        "       [ 0.21299534,  0.01685097, -0.01915576],\n",
        "       [ 0.28040822,  0.08560704, -0.20277768],\n",
        "       [ 0.20900069,  0.05125724, -0.23243211]])\n",
        "ftest_w = np.asarray([[ 0.03670967,  0.00383852, -0.01189351],\n",
        "        [-0.01396215, -0.01485459,  0.06874128],\n",
        "        [-0.02569631,  0.0213285 , -0.09259266],\n",
        "        [-0.10703647, -0.06077616,  0.19306612]])\n",
        "ftest_b = np.asarray([ 1.23669631,  0.15076511, -0.38297747])\n",
        "ftest_x = np.asarray([[ 0.03342136,  0.0654868 , -0.01645924, -0.00057441],\n",
        "        [ 0.04093848,  0.06502716, -0.00855839, -0.01959743],\n",
        "        [ 0.03014075,  0.04246176, -0.00182329, -0.02229724],\n",
        "        [ 0.04155685,  0.02000954,  0.02793369, -0.08202878],\n",
        "        [ 0.03207832, -0.00384786,  0.03407438, -0.07993428]])\n",
        "frelu = np.asarray([[ 0.24254239,  0.        ,  0.06251788],\n",
        "        [ 0.29174967,  0.00640839,  0.0088702 ],\n",
        "        [ 0.21299534,  0.01685097,  0.        ],\n",
        "        [ 0.28040822,  0.08560704,  0.        ],\n",
        "        [ 0.20900069,  0.05125724,  0.        ]])\n",
        "brelu = np.asarray([[ 0.14254239,  0.        , -0.03748212],\n",
        "       [ 0.19174967, -0.09359161, -0.0911298 ],\n",
        "       [ 0.11299534, -0.08314903,  0.        ],\n",
        "       [ 0.18040822, -0.01439296,  0.        ],\n",
        "       [ 0.10900069, -0.04874276,  0.        ]])\n",
        "ssoftmax = np.asarray([[ 0.25380621,  0.25946659,  0.17628115,  0.31044604],\n",
        "        [ 0.26931036,  0.24792319,  0.22763584,  0.25513061],\n",
        "        [ 0.21279206,  0.27229653,  0.23696266,  0.27794875],\n",
        "        [ 0.28410234,  0.26124234,  0.29367879,  0.16097652],\n",
        "        [ 0.27209608,  0.20333904,  0.33398855,  0.19057633]])\n",
        "test_y = np.asarray([3, 0, 1, 2, 1])\n",
        "test_l = 1.3201297629287778\n",
        "test_de = np.asarray([[ 0.05076124,  0.05189332,  0.03525623, -0.13791079],\n",
        "        [-0.14613793,  0.04958464,  0.04552717,  0.05102612],\n",
        "        [ 0.04255841, -0.14554069,  0.04739253,  0.05558975],\n",
        "        [ 0.05682047,  0.05224847, -0.14126424,  0.0321953 ],\n",
        "        [ 0.05441922, -0.15933219,  0.06679771,  0.03811527]])\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPXzAKV9lpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "1b1f1b18-ca7d-4996-c8ea-6a94144d31eb"
      },
      "source": [
        "# Run this block to check the values for all functions in layers.py\n",
        "print('Note: The difference between the actual values and calculated values should be <1e-7 for all functions.')\n",
        "print('')\n",
        "print('1. Checking forward_step..')\n",
        "forward_step_scores, cache = forward_step(test_x, test_w, test_b)\n",
        "diff = np.sum(np.abs(forward_step_scores - fs_scores))\n",
        "print('The difference values is: '+str(diff))\n",
        "if diff < 1e-7:\n",
        "    print('forward_step check passed ...')\n",
        "else:\n",
        "    print('forward_step check failed !!')\n",
        "print('')\n",
        "print ('2. Checking backward_step...')\n",
        "dtest_w, dtest_b, dtest_x = backward_step(fs_scores, cache)\n",
        "diff_x = np.sum(np.abs(dtest_x - ftest_x))\n",
        "diff_w = np.sum(np.abs(dtest_w - ftest_w))\n",
        "diff_b = np.sum(np.abs(dtest_b - ftest_b))\n",
        "print('The difference values for dx is: ' + str(diff_x))\n",
        "print('The difference values for dw is: ' + str(diff_w))\n",
        "print('The difference values for db is: ' + str(diff_b))\n",
        "if (diff_x < 1e-7 and diff_w < 1e-7 and diff_b < 1e-7):\n",
        "    print('backward_step check passed !!')\n",
        "else:\n",
        "    print('backward_step check failed !!')\n",
        "print('')\n",
        "print('3. Checking ReLu_forward...')\n",
        "r_score, cache = ReLu_forward(fs_scores)\n",
        "diff_relu = np.sum(np.abs(r_score - frelu))\n",
        "print('The difference value is: ' + str(diff_relu))\n",
        "if diff_relu < 1e-7:\n",
        "    print('ReLu_forward check passed !!')\n",
        "else:\n",
        "    print('ReLu_forward check failed !!')\n",
        "print('')\n",
        "print('4. Checking ReLu_backward...')\n",
        "dr_score = ReLu_backward(frelu - 0.1, cache)\n",
        "diff_relu = np.sum(np.abs(dr_score - brelu))\n",
        "print('The difference value is: ' + str(diff_relu))\n",
        "if diff_relu < 1e-7:\n",
        "    print('ReLu_backward check passed !!')\n",
        "else:\n",
        "    print('ReLu_backward check failed !!')\n",
        "print('')\n",
        "print('5. Checking softmax...')\n",
        "s_score = softmax(test_x)\n",
        "diff = np.sum(np.abs(s_score - ssoftmax))\n",
        "print('The difference values is: ' + str(diff))\n",
        "if diff < 1e-7:\n",
        "    print('softmax check passed !!')\n",
        "else:\n",
        "    print('softmax check failed !!')\n",
        "print('')\n",
        "print('6. Checking loss...')\n",
        "l, lde = loss(ssoftmax, test_y)\n",
        "diff_l = np.sum(np.abs(l - test_l))\n",
        "diff_de = np.sum(np.abs(lde - test_de))\n",
        "print('The difference between values for loss is: ' + str(diff_l))\n",
        "print('The difference between values for de is:' + str(diff_de))\n",
        "if (diff_l < 1e-7 and diff_de < 1e-7):\n",
        "    print('loss check passed !!')\n",
        "else:\n",
        "    print('loss check failed !!')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: The difference between the actual values and calculated values should be <1e-7 for all functions.\n",
            "\n",
            "1. Checking forward_step..\n",
            "The difference values is: 3.690392374848528e-08\n",
            "forward_step check passed ...\n",
            "\n",
            "2. Checking backward_step...\n",
            "The difference values for dx is: 5.7273561981582843e-08\n",
            "The difference values for dw is: 3.372888388855286e-08\n",
            "The difference values for db is: 2.220446049250313e-16\n",
            "backward_step check passed !!\n",
            "\n",
            "3. Checking ReLu_forward...\n",
            "The difference value is: 0.0\n",
            "ReLu_forward check passed !!\n",
            "\n",
            "4. Checking ReLu_backward...\n",
            "The difference value is: 8.673617379884035e-17\n",
            "ReLu_backward check passed !!\n",
            "\n",
            "5. Checking softmax...\n",
            "The difference values is: 5.824567878010001e-08\n",
            "softmax check passed !!\n",
            "\n",
            "6. Checking loss...\n",
            "The difference between values for loss is: 0.0\n",
            "The difference between values for de is:4.199999995013748e-08\n",
            "loss check passed !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "2sNqIJgp9lpv",
        "colab_type": "text"
      },
      "source": [
        "If all the checks are passed, we can now start the training of the neural network for the MNIST dataset. We start by loading the data and displaying few images with their corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guor4Pps9lpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "349aa291-ed55-46a2-aad4-c8b9125865d5"
      },
      "source": [
        "# Load the training data\n",
        "inputs, labels = load_images_with_labels()\n",
        "\n",
        "# View first 8 examples\n",
        "fig, ax = plt.subplots(1,8)\n",
        "labl = []\n",
        "for i in range(8):\n",
        "    ax[i].imshow(inputs[i], cmap=mpl.cm.Greys)\n",
        "    ax[i].set_title(labels[i])\n",
        "plt.show()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOeyZEQ19lp2",
        "colab_type": "text"
      },
      "source": [
        "Now you have the training data and corresponding labels. Each image in training data is of shape (28,28) with values ranging from 0 to 255. However, neural network cannot take data in square format. Therefore, the preprocessing includes converting each image to shape (1,784) and normalizing them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghMNSdI39lp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing the data\n",
        "train = inputs.reshape(60000, 784) # reshape the inputs shape from (60000,28,28) to (60000,784)\n",
        "train = np.float32(train) # change the datatype to float\n",
        "train /= np.max(train, axis=1).reshape(-1, 1) # Normalize the data between 0 and 1\n",
        "\n",
        "# Now we separate the inputs into training and validation\n",
        "train_ = train[0:50000,:] # We use first 50000 images for training\n",
        "tr_labels = labels[0: 50000]\n",
        "val = train[50000: 60000,:] # We use the last 10000 images for validation\n",
        "val_labels = labels[50000: 60000]\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMeP27Qg9lp8",
        "colab_type": "text"
      },
      "source": [
        "In order to simplify the training, we now define a function for forward pass which will be used in training the neural network and predicting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL3AuGpg9lp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_pass(x, w1, b1, w2, b2):\n",
        "    \"\"\"\n",
        "    TO DO: Compute the forward pass of the neural network\n",
        "    Points Allocated: 5\n",
        "    \n",
        "    Inputs:\n",
        "    x: Numpy array of shape (N,d) where N is number of samples \n",
        "    and d is the dimension of input\n",
        "    w1: numpy array of shape (d,H) where H is the size of hidden layer\n",
        "    w2: numpy array of shape (H,c) where c is the number of classes\n",
        "    b1: numpy array of shape (H,) \n",
        "    b2: numpy array of shape (c,)\n",
        "    \n",
        "    Outputs:\n",
        "    probs: output of shape (N,c)\n",
        "    cache_out: cache values for output layer\n",
        "    cache_relu: cache values for ReLu layer\n",
        "    cache_ip: cache values for input layer\n",
        "    \"\"\"\n",
        "    probs, cache_out, cache_relu, cache_ip = None, None, None, None\n",
        "    \n",
        "    ### Type your code here ###\n",
        "    fs_scores, cache_ip = forward_step(x, w1, b1)\n",
        "    relu_score, cache_relu = ReLu_forward(fs_scores)\n",
        "    fs_scores, cache_out = forward_step(relu_score, w2, b2)\n",
        "    probs = softmax(fs_scores)\n",
        "    #### End of your code #### \n",
        "    \n",
        "    return(probs,cache_out,cache_relu,cache_ip)\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmklDOud9lqD",
        "colab_type": "text"
      },
      "source": [
        "Now that you have implemented forward pass, the stochastic gradient descent algorithm works by finding the loss/error in forward pass with respect to target and traversing the error backwards. In the following function, you will implement the backward pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKTJ2LQ_9lqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_pass(probs, y, cache_out, cache_relu, cache_ip):\n",
        "    \"\"\"\n",
        "    TO DO: Compute the backward pass of the neural network\n",
        "    Points Allocated: 5\n",
        "    \n",
        "    Inputs:\n",
        "    probs: output of shape (N,c)\n",
        "    cache_out: cache values for output layer\n",
        "    cache_relu: cache values for ReLu layer\n",
        "    cache_ip: cache values for input layer\n",
        "    \n",
        "    Outputs:\n",
        "    loss_: loss value of the forward pass\n",
        "    dw2: numpy array with samw shape as w2\n",
        "    db2: numpy array with same shape as b2\n",
        "    dw1: numpy array with same shape as w1\n",
        "    db1: numpy array with same shape as b1\n",
        "    \"\"\"\n",
        "    ### Type your code here ###\n",
        "    loss_, dw_softmax = loss(probs, y)\n",
        "    dw2, db2, dx = backward_step(dw_softmax, cache_out)\n",
        "    dw_relu = ReLu_backward(dx, cache_relu)\n",
        "    dw1, db1, dx = backward_step(dw_relu, cache_ip)\n",
        "    db1, db2 = db1[0], db2[0]  # converted (1, 30) shape to (30,)    \n",
        "    #### End of your code #### \n",
        "    \n",
        "    return(loss_,dw2,db2,dw1,db1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAr4UGu39lqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following function will be used to predict the labels for given images, weights and biases\n",
        "def predict(X_batch,parameters):\n",
        "    probs, _, _, _ = forward_pass(X_batch, parameters['w1'], parameters['b1'], parameters['w2'], parameters['b2'])\n",
        "    y_pred = np.argmax(probs, axis = 1)\n",
        "    return (y_pred)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aLVButd9lqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {}\n",
        "w1 = 0.3 * np.random.randn(784, 30)\n",
        "b1 = np.zeros(30)\n",
        "w2 = 0.3 * np.random.randn(30, 10)\n",
        "b2 = np.zeros(10)\n",
        "grads={}\n",
        "loss_,grads['w1'], grads['b1'], grads['w2'], grads['b2'] = None, None, None, None, None\n",
        "val_size = 10000\n",
        "loss_history = []\n",
        "idx = np.random.choice(50000, 100, replace=True)\n",
        "x = train[idx]\n",
        "y = labels[idx]\n",
        "hi,cache_ip = forward_step(x,w1,b1)\n",
        "ho, cache_relu = ReLu_forward(hi)\n",
        "out, cache_out = forward_step(ho,w2,b2)\n",
        "probs = softmax(out)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIIQWCaE9lqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TwoLayerNN(learning_rate, num_iters, batch_size, train, labels, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Function to train the two layered neural network to predict MNIST data.\n",
        "    Inputs: \n",
        "    learning_rate: scalar value contating learning rate for training\n",
        "    num_iters: number of iterations for training\n",
        "    batch_size: number of sample used for training in each iteration\n",
        "    train: trainig data\n",
        "    labels: labels fro the training data\n",
        "    X_val: inputs for validation data\n",
        "    y_val: labels for validation data\n",
        "    \n",
        "    Output: \n",
        "    parameters: dictionary containing trained weights and biases\n",
        "    loss_history: list contating loss values for each iteration during training. It will have length of num_iters\n",
        "    \"\"\"\n",
        "    parameters = {}\n",
        "    parameters['w1'] = 0.3 * np.random.randn(784, 30)\n",
        "    parameters['b1'] = np.zeros(30)\n",
        "    parameters['w2'] = 0.3 * np.random.randn(30, 10)\n",
        "    parameters['b2'] = np.zeros(10)\n",
        "    grads={}\n",
        "    loss_, grads['w1'], grads['b1'], grads['w2'], grads['b2'] = None, None, None, None, None\n",
        "    val_size = 10000\n",
        "    loss_history = []\n",
        "    for it in range(num_iters):\n",
        "        idx = np.random.choice(50000, batch_size, replace=True)\n",
        "        X_batch = train[idx]\n",
        "        y_batch = labels[idx]\n",
        "        # The following steps implement the forward and backward pass\n",
        "        probs, cache_out, cache_relu, cache_ip = forward_pass(X_batch, parameters['w1'], parameters['b1'], parameters['w2'], parameters['b2'])\n",
        "        loss_, grads['w2'], grads['b2'], grads['w1'], grads['b1'] = backward_pass(probs, y_batch, cache_out, cache_relu, cache_ip)\n",
        "        loss_history.append(loss_)\n",
        "        #Now update the weights and biases in paramaters\n",
        "        \n",
        "        ### Type your code here ###\n",
        "        parameters['w1'] += -learning_rate * grads['w1']\n",
        "        parameters['b1'] += -learning_rate * grads['b1']\n",
        "        parameters['w2'] += -learning_rate * grads['w2']\n",
        "        parameters['b2'] += -learning_rate * grads['b2']\n",
        "        #### End of your code #### \n",
        "        \n",
        "        train_acc = (predict(X_batch, parameters) == y_batch).mean()\n",
        "        val_acc = (predict(X_val, parameters) == y_val).mean()\n",
        "        \n",
        "        if it % 10 == 0:\n",
        "            print ('iteration '+str(it) + ' / '+ str(num_iters) +' :loss ' + str(loss_))\n",
        "            print('training accuracy: '+ str(train_acc) + ' and validation accuracy: '+ str(val_acc))\n",
        "    return (parameters,loss_history)    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JQ2A1Wx9lqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fef046f-a07f-4903-bb05-90b13afb6bd4"
      },
      "source": [
        "parameters, loss_history = TwoLayerNN(0.1, 1000, 200, train_, tr_labels, val, val_labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 / 1000 :loss 7.230971839550665\n",
            "training accuracy: 0.115 and validation accuracy: 0.0832\n",
            "iteration 10 / 1000 :loss 2.163604680522244\n",
            "training accuracy: 0.32 and validation accuracy: 0.2891\n",
            "iteration 20 / 1000 :loss 1.7834393206319994\n",
            "training accuracy: 0.45 and validation accuracy: 0.4076\n",
            "iteration 30 / 1000 :loss 1.5526006654750006\n",
            "training accuracy: 0.525 and validation accuracy: 0.4907\n",
            "iteration 40 / 1000 :loss 1.4211991824857517\n",
            "training accuracy: 0.475 and validation accuracy: 0.5502\n",
            "iteration 50 / 1000 :loss 1.3057672086753738\n",
            "training accuracy: 0.555 and validation accuracy: 0.6024\n",
            "iteration 60 / 1000 :loss 1.174961143532204\n",
            "training accuracy: 0.66 and validation accuracy: 0.6458\n",
            "iteration 70 / 1000 :loss 0.9946966470342267\n",
            "training accuracy: 0.7 and validation accuracy: 0.6769\n",
            "iteration 80 / 1000 :loss 0.9837470174430138\n",
            "training accuracy: 0.71 and validation accuracy: 0.7028\n",
            "iteration 90 / 1000 :loss 0.7978020758485832\n",
            "training accuracy: 0.755 and validation accuracy: 0.7265\n",
            "iteration 100 / 1000 :loss 0.8952412794415315\n",
            "training accuracy: 0.725 and validation accuracy: 0.7408\n",
            "iteration 110 / 1000 :loss 0.8419615300435336\n",
            "training accuracy: 0.765 and validation accuracy: 0.7531\n",
            "iteration 120 / 1000 :loss 0.8152213934234669\n",
            "training accuracy: 0.77 and validation accuracy: 0.7692\n",
            "iteration 130 / 1000 :loss 0.7867583507915897\n",
            "training accuracy: 0.775 and validation accuracy: 0.7796\n",
            "iteration 140 / 1000 :loss 0.6513108220686312\n",
            "training accuracy: 0.81 and validation accuracy: 0.7891\n",
            "iteration 150 / 1000 :loss 0.597815889153559\n",
            "training accuracy: 0.805 and validation accuracy: 0.7962\n",
            "iteration 160 / 1000 :loss 0.6619463765242607\n",
            "training accuracy: 0.82 and validation accuracy: 0.8053\n",
            "iteration 170 / 1000 :loss 0.6504300742461427\n",
            "training accuracy: 0.82 and validation accuracy: 0.81\n",
            "iteration 180 / 1000 :loss 0.5676815347130976\n",
            "training accuracy: 0.805 and validation accuracy: 0.8153\n",
            "iteration 190 / 1000 :loss 0.6313856157345512\n",
            "training accuracy: 0.805 and validation accuracy: 0.8193\n",
            "iteration 200 / 1000 :loss 0.5964734946607498\n",
            "training accuracy: 0.84 and validation accuracy: 0.8254\n",
            "iteration 210 / 1000 :loss 0.5891872462053791\n",
            "training accuracy: 0.825 and validation accuracy: 0.8319\n",
            "iteration 220 / 1000 :loss 0.5394961423817515\n",
            "training accuracy: 0.805 and validation accuracy: 0.8358\n",
            "iteration 230 / 1000 :loss 0.5885610874806364\n",
            "training accuracy: 0.86 and validation accuracy: 0.8371\n",
            "iteration 240 / 1000 :loss 0.6045397774087697\n",
            "training accuracy: 0.875 and validation accuracy: 0.845\n",
            "iteration 250 / 1000 :loss 0.4602790131944954\n",
            "training accuracy: 0.87 and validation accuracy: 0.8404\n",
            "iteration 260 / 1000 :loss 0.4855916725191047\n",
            "training accuracy: 0.85 and validation accuracy: 0.8491\n",
            "iteration 270 / 1000 :loss 0.497136822477472\n",
            "training accuracy: 0.865 and validation accuracy: 0.8499\n",
            "iteration 280 / 1000 :loss 0.5721735524445465\n",
            "training accuracy: 0.815 and validation accuracy: 0.8533\n",
            "iteration 290 / 1000 :loss 0.5290347873083785\n",
            "training accuracy: 0.855 and validation accuracy: 0.8578\n",
            "iteration 300 / 1000 :loss 0.41194123909584834\n",
            "training accuracy: 0.875 and validation accuracy: 0.859\n",
            "iteration 310 / 1000 :loss 0.4643125188628162\n",
            "training accuracy: 0.845 and validation accuracy: 0.8602\n",
            "iteration 320 / 1000 :loss 0.555763177337836\n",
            "training accuracy: 0.86 and validation accuracy: 0.8621\n",
            "iteration 330 / 1000 :loss 0.5729748674091111\n",
            "training accuracy: 0.79 and validation accuracy: 0.8635\n",
            "iteration 340 / 1000 :loss 0.44250391576666814\n",
            "training accuracy: 0.88 and validation accuracy: 0.866\n",
            "iteration 350 / 1000 :loss 0.5469421694431041\n",
            "training accuracy: 0.86 and validation accuracy: 0.8661\n",
            "iteration 360 / 1000 :loss 0.42190274478683504\n",
            "training accuracy: 0.87 and validation accuracy: 0.8692\n",
            "iteration 370 / 1000 :loss 0.3831745199018412\n",
            "training accuracy: 0.9 and validation accuracy: 0.8714\n",
            "iteration 380 / 1000 :loss 0.4326399929916222\n",
            "training accuracy: 0.875 and validation accuracy: 0.866\n",
            "iteration 390 / 1000 :loss 0.5256903777513849\n",
            "training accuracy: 0.835 and validation accuracy: 0.873\n",
            "iteration 400 / 1000 :loss 0.40693713744619275\n",
            "training accuracy: 0.895 and validation accuracy: 0.8728\n",
            "iteration 410 / 1000 :loss 0.43260467338375946\n",
            "training accuracy: 0.88 and validation accuracy: 0.8748\n",
            "iteration 420 / 1000 :loss 0.4552903875930089\n",
            "training accuracy: 0.845 and validation accuracy: 0.8742\n",
            "iteration 430 / 1000 :loss 0.4373796793201912\n",
            "training accuracy: 0.87 and validation accuracy: 0.8765\n",
            "iteration 440 / 1000 :loss 0.45066520185517833\n",
            "training accuracy: 0.86 and validation accuracy: 0.878\n",
            "iteration 450 / 1000 :loss 0.35859515110434836\n",
            "training accuracy: 0.9 and validation accuracy: 0.8804\n",
            "iteration 460 / 1000 :loss 0.47190169486195993\n",
            "training accuracy: 0.865 and validation accuracy: 0.881\n",
            "iteration 470 / 1000 :loss 0.5023460350218274\n",
            "training accuracy: 0.865 and validation accuracy: 0.8802\n",
            "iteration 480 / 1000 :loss 0.3865374437354446\n",
            "training accuracy: 0.895 and validation accuracy: 0.8827\n",
            "iteration 490 / 1000 :loss 0.5140782717078919\n",
            "training accuracy: 0.865 and validation accuracy: 0.8824\n",
            "iteration 500 / 1000 :loss 0.4868088031508349\n",
            "training accuracy: 0.88 and validation accuracy: 0.8818\n",
            "iteration 510 / 1000 :loss 0.33349186309975876\n",
            "training accuracy: 0.935 and validation accuracy: 0.8844\n",
            "iteration 520 / 1000 :loss 0.3765004521476054\n",
            "training accuracy: 0.89 and validation accuracy: 0.8816\n",
            "iteration 530 / 1000 :loss 0.3499324674040433\n",
            "training accuracy: 0.88 and validation accuracy: 0.8857\n",
            "iteration 540 / 1000 :loss 0.4090010333714917\n",
            "training accuracy: 0.89 and validation accuracy: 0.8848\n",
            "iteration 550 / 1000 :loss 0.46205729503161913\n",
            "training accuracy: 0.87 and validation accuracy: 0.8889\n",
            "iteration 560 / 1000 :loss 0.3286534903755776\n",
            "training accuracy: 0.915 and validation accuracy: 0.8884\n",
            "iteration 570 / 1000 :loss 0.3214550721419063\n",
            "training accuracy: 0.91 and validation accuracy: 0.8898\n",
            "iteration 580 / 1000 :loss 0.4201616670743125\n",
            "training accuracy: 0.885 and validation accuracy: 0.8906\n",
            "iteration 590 / 1000 :loss 0.36456367187193595\n",
            "training accuracy: 0.9 and validation accuracy: 0.891\n",
            "iteration 600 / 1000 :loss 0.33243648903189366\n",
            "training accuracy: 0.925 and validation accuracy: 0.8923\n",
            "iteration 610 / 1000 :loss 0.2908188010594843\n",
            "training accuracy: 0.915 and validation accuracy: 0.8937\n",
            "iteration 620 / 1000 :loss 0.5503994883116893\n",
            "training accuracy: 0.855 and validation accuracy: 0.894\n",
            "iteration 630 / 1000 :loss 0.3853362828078929\n",
            "training accuracy: 0.91 and validation accuracy: 0.8926\n",
            "iteration 640 / 1000 :loss 0.2769283829767737\n",
            "training accuracy: 0.915 and validation accuracy: 0.895\n",
            "iteration 650 / 1000 :loss 0.4038609696365291\n",
            "training accuracy: 0.89 and validation accuracy: 0.8935\n",
            "iteration 660 / 1000 :loss 0.2894721077119909\n",
            "training accuracy: 0.94 and validation accuracy: 0.8943\n",
            "iteration 670 / 1000 :loss 0.31983946276321773\n",
            "training accuracy: 0.905 and validation accuracy: 0.8963\n",
            "iteration 680 / 1000 :loss 0.3407968194388678\n",
            "training accuracy: 0.905 and validation accuracy: 0.8959\n",
            "iteration 690 / 1000 :loss 0.2675012890033069\n",
            "training accuracy: 0.93 and validation accuracy: 0.897\n",
            "iteration 700 / 1000 :loss 0.311931650820209\n",
            "training accuracy: 0.9 and validation accuracy: 0.8973\n",
            "iteration 710 / 1000 :loss 0.3669235364580821\n",
            "training accuracy: 0.895 and validation accuracy: 0.8968\n",
            "iteration 720 / 1000 :loss 0.2728791376354098\n",
            "training accuracy: 0.935 and validation accuracy: 0.8991\n",
            "iteration 730 / 1000 :loss 0.32029810325362773\n",
            "training accuracy: 0.885 and validation accuracy: 0.8998\n",
            "iteration 740 / 1000 :loss 0.2825210027381901\n",
            "training accuracy: 0.91 and validation accuracy: 0.9003\n",
            "iteration 750 / 1000 :loss 0.35557348466087857\n",
            "training accuracy: 0.9 and validation accuracy: 0.9021\n",
            "iteration 760 / 1000 :loss 0.486335666922344\n",
            "training accuracy: 0.89 and validation accuracy: 0.8993\n",
            "iteration 770 / 1000 :loss 0.3289716534953411\n",
            "training accuracy: 0.915 and validation accuracy: 0.9015\n",
            "iteration 780 / 1000 :loss 0.4215654139341252\n",
            "training accuracy: 0.905 and validation accuracy: 0.9024\n",
            "iteration 790 / 1000 :loss 0.27414800182104937\n",
            "training accuracy: 0.93 and validation accuracy: 0.8992\n",
            "iteration 800 / 1000 :loss 0.4254722892385072\n",
            "training accuracy: 0.875 and validation accuracy: 0.9029\n",
            "iteration 810 / 1000 :loss 0.35847745025182925\n",
            "training accuracy: 0.9 and validation accuracy: 0.9025\n",
            "iteration 820 / 1000 :loss 0.4242875683841102\n",
            "training accuracy: 0.865 and validation accuracy: 0.9011\n",
            "iteration 830 / 1000 :loss 0.25562943625615253\n",
            "training accuracy: 0.925 and validation accuracy: 0.904\n",
            "iteration 840 / 1000 :loss 0.3515064900124095\n",
            "training accuracy: 0.91 and validation accuracy: 0.9033\n",
            "iteration 850 / 1000 :loss 0.2715145041502199\n",
            "training accuracy: 0.935 and validation accuracy: 0.904\n",
            "iteration 860 / 1000 :loss 0.42061804885504855\n",
            "training accuracy: 0.915 and validation accuracy: 0.9052\n",
            "iteration 870 / 1000 :loss 0.3030635009416178\n",
            "training accuracy: 0.915 and validation accuracy: 0.9054\n",
            "iteration 880 / 1000 :loss 0.2314412133487628\n",
            "training accuracy: 0.95 and validation accuracy: 0.9066\n",
            "iteration 890 / 1000 :loss 0.3802620121643971\n",
            "training accuracy: 0.88 and validation accuracy: 0.9056\n",
            "iteration 900 / 1000 :loss 0.3280361470385894\n",
            "training accuracy: 0.91 and validation accuracy: 0.9073\n",
            "iteration 910 / 1000 :loss 0.4653838836916065\n",
            "training accuracy: 0.9 and validation accuracy: 0.9062\n",
            "iteration 920 / 1000 :loss 0.40954636488360996\n",
            "training accuracy: 0.875 and validation accuracy: 0.9085\n",
            "iteration 930 / 1000 :loss 0.3842317840722112\n",
            "training accuracy: 0.905 and validation accuracy: 0.9077\n",
            "iteration 940 / 1000 :loss 0.33088984386110804\n",
            "training accuracy: 0.915 and validation accuracy: 0.9093\n",
            "iteration 950 / 1000 :loss 0.3328053962152056\n",
            "training accuracy: 0.915 and validation accuracy: 0.9079\n",
            "iteration 960 / 1000 :loss 0.3135151157358719\n",
            "training accuracy: 0.915 and validation accuracy: 0.9083\n",
            "iteration 970 / 1000 :loss 0.3008411683961396\n",
            "training accuracy: 0.9 and validation accuracy: 0.9073\n",
            "iteration 980 / 1000 :loss 0.34880190889386015\n",
            "training accuracy: 0.92 and validation accuracy: 0.9093\n",
            "iteration 990 / 1000 :loss 0.3336574669956038\n",
            "training accuracy: 0.9 and validation accuracy: 0.9101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y729JQy9lqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a8b340ad-6a19-4471-b560-dec82cefda1b"
      },
      "source": [
        "# plot the loss to see how the loss varied over iterations\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('training loss')\n",
        "plt.title('Training Loss history')\n",
        "plt.show()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvurG86T9lqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading and pre=processing test data\n",
        "t_inputs, tlabels = load_images_with_labels(type_of_data='testing')\n",
        "tinputs = t_inputs.reshape(10000, 784)\n",
        "tinputs = np.float32(tinputs)\n",
        "tinputs /= np.max(tinputs,axis=1).reshape(-1, 1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyJO0P99lqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "473ed11e-9b0e-4a64-d5e8-11c7d565d030"
      },
      "source": [
        "# Calculate the accuracy on test data using trained weights and biases\n",
        "pred = predict(tinputs, parameters)\n",
        "test_acc = (pred == tlabels).mean()\n",
        "print(test_acc)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQjF7n939lqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2ae2aad4-9c60-4f35-c90d-374724bd4954"
      },
      "source": [
        "# Predict the labels for n images for visual representation\n",
        "n = 5 # number of images to predict\n",
        "idx = np.random.choice(10000, n, replace=False) # select n random images from test data\n",
        "labl=[]\n",
        "# View first n examples\n",
        "fig, ax = plt.subplots(1,n)\n",
        "for i, val in enumerate(idx):\n",
        "    ax[i].imshow(t_inputs[val], cmap=mpl.cm.Greys)\n",
        "    ax[i].set_title(tlabels[val])\n",
        "    labl.append(pred[val])\n",
        "plt.show()\n",
        "\n",
        "print('Corresponding predictions of labels for each of the above images: '+ str(labl))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Corresponding predictions of labels for each of the above images: [1, 8, 5, 8, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}